import aiohttp
import asyncio
from bs4 import BeautifulSoup
 
async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()
 
async def main():
    urls = ['http://example.com/page1', 'http://example.com/page2']
    async with aiohttp.ClientSession() as session:
        tasks = [fetch(session, url) for url in urls]
        responses = await asyncio.gather(*tasks)
 
        for response in responses:
            soup = BeautifulSoup(response, 'html.parser')
            for item in soup.find_all('a'):
                title = item.get_text()
                link = item.get('href')
                print(f'Title: {title}, Link: {link}')
 
asyncio.run(main())
